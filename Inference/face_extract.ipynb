{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dlib\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "from os.path import join\n",
    "import dlib\n",
    "from PIL import Image as pil_image\n",
    "from PIL import Image\n",
    "import torch\n",
    "import cv2\n",
    "import time\n",
    "from os import cpu_count\n",
    "import multiprocessing as mp\n",
    "from multiprocessing.pool import Pool\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from glob import glob\n",
    "from tqdm import tqdm \n",
    "import numpy as np\n",
    "from functools import partial \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_boundingbox(face, width, height, scale=1.3, minsize=None):\n",
    "    \"\"\"\n",
    "    Expects a dlib face to generate a quadratic bounding box.\n",
    "    :param face: dlib face class\n",
    "    :param width: frame width\n",
    "    :param height: frame height\n",
    "    :param scale: bounding box size multiplier to get a bigger face region\n",
    "    :param minsize: set minimum bounding box size\n",
    "    :return: x, y, bounding_box_size in opencv form\n",
    "    \"\"\"\n",
    "    x1 = face.left()\n",
    "    y1 = face.top()\n",
    "    x2 = face.right()\n",
    "    y2 = face.bottom()\n",
    "    size_bb = int(max(x2 - x1, y2 - y1) * scale)\n",
    "    if minsize:\n",
    "        if size_bb < minsize:\n",
    "            size_bb = minsize\n",
    "    center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "\n",
    "    # Check for out of bounds, x-y top left corner\n",
    "    x1 = max(int(center_x - size_bb // 2), 0)\n",
    "    y1 = max(int(center_y - size_bb // 2), 0)\n",
    "    # Check for too big bb size for given x, y\n",
    "    size_bb = min(width - x1, size_bb)\n",
    "    size_bb = min(height - y1, size_bb)\n",
    "\n",
    "    return x1, y1, size_bb\n",
    "\n",
    "def biggest_face_idx(faces):\n",
    "    max_area = 0\n",
    "    max_idx = 0\n",
    "    for idx, face in enumerate(faces):\n",
    "        x1 = face.left()\n",
    "        y1 = face.top()\n",
    "        x2 = face.right()\n",
    "        y2 = face.bottom()\n",
    "        area_idx = (x2 - x1) * (y2 - y1)\n",
    "        if area_idx > max_area:\n",
    "            max_area = area_idx\n",
    "            max_idx = idx\n",
    "    return max_idx\n",
    "\n",
    "    \n",
    "def save_face(filename, des_dir, margin_scale=1.3):\n",
    "    \"Read file - Get face - Save file\"\n",
    "    video_name = filename.split('/')[-1][:-4] # Not include '.mp4'\n",
    "    print(video_name)\n",
    "    folder_save = des_dir+ '/' + video_name + '/'\n",
    "    print(folder_save)\n",
    "    # if 'raw' in filename:\n",
    "    face_locate = OrderedDict() # Dictionnary to save face rectangle cropping\n",
    "\n",
    "    os.makedirs(folder_save, exist_ok=True)\n",
    "    # print(len(os.listdir(folder_save)))\n",
    "\n",
    "\n",
    "    reader = cv2.VideoCapture(filename)\n",
    "    frame_num = 0\n",
    "    while reader.isOpened():\n",
    "        success, image = reader.read()\n",
    "        if not success:\n",
    "            break\n",
    "        if image is None:\n",
    "            continue\n",
    "        height, width = image.shape[:2]\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_detector(gray, 1)\n",
    "        if len(faces):\n",
    "            face_idx = 0 if len(faces)==1 else biggest_face_idx(faces)\n",
    "            # For now only take biggest face\n",
    "            face = faces[face_idx]\n",
    "            x, y, size = get_boundingbox(face, width, height, scale=margin_scale)\n",
    "            cropped_face = image[y:y+size, x:x+size]\n",
    "            file_save = os.path.join(folder_save, '{:04d}.png'.format(frame_num))\n",
    "            # if os.path.exists(file_save):\n",
    "            #         continue\n",
    "            success_ = False\n",
    "            try: \n",
    "                cv2.imwrite(file_save, cropped_face)\n",
    "                success_ = True\n",
    "            except: \n",
    "                pass\n",
    "            if success_:\n",
    "                face_locate[frame_num] = [x, y, size]\n",
    "        frame_num += 1 \n",
    "                         \n",
    "    print('NUmber of frame counted: ', frame_num)           \n",
    "    reader.release()       \n",
    "    with open(os.path.join(folder_save, 'face_locate.json'), 'w') as outfile:\n",
    "            json.dump(face_locate, outfile)\n",
    "    return 1\n",
    "    \n",
    "def sanity_check(filename, des_dir):\n",
    "    \"Read file - Get face - Save file\"\n",
    "    video_name = filename.split('/')[-1][:-4] # Not include '.mp4'\n",
    "    folder_save = des_dir  + video_name + '/'\n",
    "\n",
    "    os.makedirs(folder_save, exist_ok=True)\n",
    "    # print(len(os.listdir(folder_save)))\n",
    "    if len(os.listdir(folder_save)) < 120: \n",
    "        print(video_name, len(os.listdir(folder_save)))\n",
    "    return 1\n",
    "\n",
    "\n",
    "face_detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15__walk_down_hall_angry_converted_1\n",
      "face_output/15__walk_down_hall_angry_converted_1/\n",
      "NUmber of frame counted:  549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Extract face in each frame by dlib\")\n",
    "    parser.add_argument(\"-g\", \"--gpus\", help=\"GPUS\", default=\"1, 2, 3\", type=str)\n",
    "    parser.add_argument(\"-rd\", \"--video\", help=\"Input video\", type=str)\n",
    "    parser.add_argument(\"-dd\", \"--output-folder\", help=\"Output directory\", default='None')\n",
    "    parser.add_argument(\"-ms\", \"--margin_scale\", help=\"margin scaling\", default=1.3, type=float)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "args = parse_args()\n",
    "'''\n",
    "output_folder = 'face_output'\n",
    "video = '/media/data2/jiwon/CSIRO/0115/dfaker/15__walk_down_hall_angry_converted_1.mp4'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "save_face(video, des_dir=output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intern2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11e961a22b66e19e16895e62ca9df0d30d6863894a2b0a5a1a7d6c8da8ab4f25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
